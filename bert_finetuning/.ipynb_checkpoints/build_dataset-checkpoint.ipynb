{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "555a82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09e7a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path1='entailment_trees_emnlp2021_data_v3/dataset/task_1/train.jsonl'\n",
    "read_path2='fullresult.jsonlines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "598c37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(read_path1,read_path2):\n",
    "    import jsonlines\n",
    "    import re\n",
    "    dict_hypo_theoryset={}\n",
    "    \n",
    "    pattern = r'sent\\d+: '\n",
    "    with jsonlines.open(read_path1, \"r\") as rfd:\n",
    "        for data in rfd:\n",
    "            result = re.split(pattern, data['context'])\n",
    "            result_n = set([x.strip() for x in result if x.strip()!=''])\n",
    "            dict_hypo_theoryset[data['hypothesis']]=result_n\n",
    "    rfd.close()\n",
    "    \n",
    "    theory=[]\n",
    "    pos_hypo=[]\n",
    "    for hypo in dict_hypo_theoryset.keys():\n",
    "        para=\"\"\n",
    "        for sent in dict_hypo_theoryset[hypo]:\n",
    "            para+=sent+'. '\n",
    "        theory.append(para.strip())\n",
    "        pos_hypo.append(hypo)\n",
    "        \n",
    "    neg_hypo=[]\n",
    "    \n",
    "    with jsonlines.open(read_path2, \"r\") as rfd:\n",
    "        for data in rfd:\n",
    "            for key in data.keys():\n",
    "                neg_hypo.append(data[key].split('.'))\n",
    "    rfd.close()        \n",
    "    \n",
    "    \n",
    "    return theory,pos_hypo,neg_hypo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d81294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1276\n",
      "1276\n",
      "1276\n"
     ]
    }
   ],
   "source": [
    "theory,pos_hypo,neg_hypo=read_data(read_path1,read_path2)\n",
    "print(len(theory))\n",
    "print(len(pos_hypo))\n",
    "print(len(neg_hypo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35a9c9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "venus is covered in highly reflective clouds. as the light reflected off of an object increases , the object will appear to be brighter. more light gets reflected on highly reflective things.\n"
     ]
    }
   ],
   "source": [
    "print(theory[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70821c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "a=np.array([len(i) for i in theory])\n",
    "x=np.argmax(a)\n",
    "print(x)\n",
    "print(np.sum(a>500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70edf8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"an arctic fox is a kind of animal. color is a property of something that describes how that something looks. some environments change color. snow falls during the winter in the arctic environment. an example of camouflage is an organism looking like its environment. if something is one color during one time and another color during another time, then at something changes color. when snow in an environment melts, that environment will become dark gray or brown. snow melts during the summer in an arctic environment. camouflage is used for protection / hiding by prey / animals against predators / from predators. hiding means ability to be seen decreases for camouflage. an arctic fox's fur is dark gray or brown in the summer. to blend into something means to be less able to see in something. an animal is a kind of organism. an arctic fox's fur is white in the winter. if an animal 's fur is a color then that animal is that color. when snow falls in an environment in an environment , that environment will become white.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theory[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91d845a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"color is a property of something that describes how that something looks. an example of camouflage is an organism looking like its environment. a chameleon can change colors. some environments change colors. avoiding predators has a positive impact on an organism 's survival. an animal is a kind of organism. camouflage is used for hiding by animals from predators. hiding can be used to avoid something.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theory[599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_padding(data,max_len):\n",
    "    if len(data)<max_len:\n",
    "        pad_len=max_len-len(data)\n",
    "        padding=[0 for _ in range(pad_len)]\n",
    "        data=torch.tensor(data+padding)\n",
    "    else:\n",
    "        data=torch.tensor(data[:,max_len])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "621cae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(pos,neg,theory):\n",
    "    data={'theory':[],'neg':[],'pos':[]}\n",
    "    for i,t in enumerate(theory):\n",
    "        data['theory'].append(t)\n",
    "        data['neg'].append(neg[i])\n",
    "        data['pos'].append(pos[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebf623ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=get_data(pos_hypo,neg_hypo,theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "443739e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b985991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputDataset(Dataset):\n",
    "    def __init__(self, data,tokenizer,sent_len,data_size):\n",
    "        self.data=data\n",
    "        self.sent_len=sent_len\n",
    "        self.data_size=data_size\n",
    "        self.tokenizer=tokenizer\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return self.data_size\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        x=np.random.rand(1)*100\n",
    "        if x[0]<=25:\n",
    "            label=1\n",
    "            hypo=self.data['pos'][item]\n",
    "        else:\n",
    "            label=0\n",
    "            hypo=np.random.choice(self.data['neg'][item])\n",
    "        label=torch.tensor(label,dtype=torch.long)\n",
    "        theory=self.data['theory'][item]\n",
    "        \n",
    "        encoding=self.tokenizer.encode_plus(\n",
    "            theory,\n",
    "            hypo,\n",
    "            add_special_tokens=True, #add [CLS] and [SEP]\n",
    "            max_length=self.sent_len,#max input length\n",
    "            return_token_type_ids=True,#theory 11111 and hypo 00000\n",
    "            pad_to_max_length=True,# fill or cut up to max input length \n",
    "            return_attention_mask=True,# attention encoding\n",
    "            return_tensors='pt'# pytorch model\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"theory\":theory,\n",
    "            \"hypo\":hypo,\n",
    "            \"input_ids\":encoding['input_ids'].flatten(),\n",
    "            \"attention_mask\":encoding['attention_mask'],\n",
    "            \"token_type_ids\":encoding['token_type_ids'],\n",
    "            \"label\":label\n",
    "        }\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9b016c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset=InputDataset(data,tokenizer,500,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f0353083",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader=DataLoader(train_dataset,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ac2085fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "batch=next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fde51e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
