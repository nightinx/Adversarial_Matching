{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b3eac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f259c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path1='entailment_trees_emnlp2021_data_v3/dataset/task_1/train.jsonl'\n",
    "read_path2='fullresult.jsonlines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72432018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(read_path1,read_path2):\n",
    "    import jsonlines\n",
    "    import re\n",
    "    dict_hypo_theoryset={}\n",
    "    \n",
    "    pattern = r'sent\\d+: '\n",
    "    with jsonlines.open(read_path1, \"r\") as rfd:\n",
    "        for data in rfd:\n",
    "            result = re.split(pattern, data['context'])\n",
    "            result_n = set([x.strip() for x in result if x.strip()!=''])\n",
    "            dict_hypo_theoryset[data['hypothesis']]=result_n\n",
    "    rfd.close()\n",
    "    \n",
    "    theory=[]\n",
    "    pos_hypo=[]\n",
    "    for hypo in dict_hypo_theoryset.keys():\n",
    "        para=\"\"\n",
    "        for sent in dict_hypo_theoryset[hypo]:\n",
    "            para+=sent+'. '\n",
    "        theory.append(para.strip())\n",
    "        pos_hypo.append([hypo])\n",
    "        \n",
    "    neg_hypo=[]\n",
    "    \n",
    "    with jsonlines.open(read_path2, \"r\") as rfd:\n",
    "        for data in rfd:\n",
    "            for key in data.keys():\n",
    "                neg_hypo.append(data[key].split('.'))\n",
    "               \n",
    "    rfd.close()        \n",
    "    \n",
    "    \n",
    "    return theory,pos_hypo,neg_hypo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac97fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_padding(data,max_len):\n",
    "    if len(data)<max_len:\n",
    "        pad_len=max_len-len(data)\n",
    "        padding=[0 for _ in range(pad_len)]\n",
    "        data=torch.tensor(data+padding)\n",
    "    else:\n",
    "        data=torch.tensor(data[:,max_len])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "549fb93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(pos_hypo,neg_hypo,theory):\n",
    "    data={'theory':[],'neg':[],'pos':[]}\n",
    "    for i,t in enumerate(theory):\n",
    "        data['theory'].append(t)\n",
    "        data['neg'].append(neg_hypo[i])\n",
    "        data['pos'].append(pos_hypo[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cfe1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "theory,pos_hypo,neg_hypo=read_data(read_path1,read_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e22657ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=get_data(pos_hypo,neg_hypo,theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "269a7cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the earth rotating on its axis causes stars to move relative to the horizon during the night\n"
     ]
    }
   ],
   "source": [
    "print(pos_hypo[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6378afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68fbee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputDataset(Dataset):\n",
    "    def __init__(self, data,tokenizer,sent_len,data_size,split=0.8,mode='train'):\n",
    "        self.data=data\n",
    "        self.sent_len=sent_len\n",
    "        self.data_size=data_size\n",
    "        self.tokenizer=tokenizer\n",
    "        self.split=split\n",
    "        self.mode=mode\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return self.data_size\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        x=np.random.rand(1)*100\n",
    "        assert self.mode in ['train','test'],\"mode must be train or test\"\n",
    "        if self.mode=='train':\n",
    "            item=item%(int(len(data['theory'])*self.split))\n",
    "        elif self.mode=='test':\n",
    "            item=item%(int(len(data['theory'])*self.split))+int((1-split)*len(data['theory']))\n",
    "        \n",
    "            \n",
    "        if x[0]<=25:\n",
    "            label=1\n",
    "            hypo=self.data['pos'][item][0]\n",
    "        else:\n",
    "            label=0\n",
    "            hypo=random.choice(self.data['neg'][item])\n",
    "        label=torch.tensor(label,dtype=torch.long)\n",
    "        theory=self.data['theory'][item]\n",
    "        \n",
    "        encoding=self.tokenizer.encode_plus(\n",
    "            theory,\n",
    "            hypo,\n",
    "            add_special_tokens=True, #add [CLS] and [SEP]\n",
    "            max_length=self.sent_len,#max input length\n",
    "            return_token_type_ids=True,#theory 11111 and hypo 00000\n",
    "            pad_to_max_length=True,# fill or cut up to max input length \n",
    "            return_attention_mask=True,# attention encoding\n",
    "            return_tensors='pt'# pytorch model\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"theory\":theory,\n",
    "            \"hypo\":hypo,\n",
    "            \"input_ids\":encoding['input_ids'].flatten(),\n",
    "            \"attention_mask\":encoding['attention_mask'],\n",
    "            \"token_type_ids\":encoding['token_type_ids'],\n",
    "            \"label\":label\n",
    "        }\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0b97abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset=InputDataset(data,tokenizer,500,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97b65836",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader=DataLoader(train_dataset,batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e03b8c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "batch=next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a43464cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theory': ['the earth revolving around the sun causes stars to appear in different areas in the sky at different times of year. leo is a kind of constellation. a constellation contains stars.', \"apparent motion is when an object appears to move relative to another object 's position. the earth rotating on its axis causes stars to appear to move across the sky at night. a star is a kind of celestial object / celestial body. stars appear to move relative to the horizon during the night. earth is a kind of celestial object.\"], 'hypo': [' cold leo will cause rain / year as they pass by', \" earth has a positive stars on a rabbit 's night in a winter axis\"], 'input_ids': tensor([[  101,  1996,  3011, 24135,  2105,  1996,  3103,  5320,  3340,  2000,\n",
      "          3711,  1999,  2367,  2752,  1999,  1996,  3712,  2012,  2367,  2335,\n",
      "          1997,  2095,  1012,  6688,  2003,  1037,  2785,  1997, 15300,  1012,\n",
      "          1037, 15300,  3397,  3340,  1012,   102,  3147,  6688,  2097,  3426,\n",
      "          4542,  1013,  2095,  2004,  2027,  3413,  2011,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6835,  4367,  2003,  2043,  2019,  4874,  3544,  2000,  2693,\n",
      "          5816,  2000,  2178,  4874,  1005,  1055,  2597,  1012,  1996,  3011,\n",
      "         13618,  2006,  2049,  8123,  5320,  3340,  2000,  3711,  2000,  2693,\n",
      "          2408,  1996,  3712,  2012,  2305,  1012,  1037,  2732,  2003,  1037,\n",
      "          2785,  1997, 17617,  4874,  1013, 17617,  2303,  1012,  3340,  3711,\n",
      "          2000,  2693,  5816,  2000,  1996,  9154,  2076,  1996,  2305,  1012,\n",
      "          3011,  2003,  1037,  2785,  1997, 17617,  4874,  1012,   102,  3011,\n",
      "          2038,  1037,  3893,  3340,  2006,  1037, 10442,  1005,  1055,  2305,\n",
      "          1999,  1037,  3467,  8123,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]), 'token_type_ids': tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]), 'label': tensor([0, 0])}\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c1c45df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel,BertPreTrainedModel,BertConfig\n",
    "class BertForSeq(BertPreTrainedModel):\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        super(BertForSeq,self).__init__(config)\n",
    "        self.config=BertConfig(config)\n",
    "        self.num_labels=config.num_labels #set to 1, it's a logit\n",
    "        self.bert=BertModel(config)   \n",
    "        self.dropout=nn.Dropout(config.hidden_derpout_prob)\n",
    "        self.classifier=nn.Linear(config._hidden_size,self.num_labels)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self,input_ids,attention_mask=None,token_type_ids=None,return_dict=None ):\n",
    "        return_dict=return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs=self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=return_dict\n",
    "        ) #prediction\n",
    "\n",
    "        pooled_output=outputs[1]\n",
    "        pooled_output=self.dropout(pooled_output)\n",
    "        logits=self.classifier(pooled_output)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "30a7b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output, targets):\n",
    "    return nn.BCEWithLogitsLoss()(output, targets.view(-1,1))\n",
    "\n",
    "def train_func(data_loader, model, optimizer, device, scheduler):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d[\"input_ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"attention_mask\"]\n",
    "        targets = d[\"label\"]\n",
    "        \n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(\n",
    "            input_ids=ids,\n",
    "            attention_mask = mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(output, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "def eval_func(data_loader, model, device):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets = []\n",
    "    fin_output = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"input_ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"attention_mask\"]\n",
    "            targets = d[\"label\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.long)\n",
    "\n",
    "\n",
    "            output = model(\n",
    "                input_ids=ids,\n",
    "                attention_mask = mask,\n",
    "                token_type_ids = token_type_ids\n",
    "            )\n",
    "        \n",
    "            fin_targets.extend(targets.cpu().detach().numpy().to_list())\n",
    "            fin_targets.extend(torch.sigmoid(output).cpu().detach().numpy().to_list())\n",
    "            \n",
    "        return fin_output, fin_targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "\n",
    "    df_train, df_valid = train_test_split(data, test_size = 0.1, random_state=23, stratify=data.label.values)\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_valid = df_valid.reset_index(drop=True)\n",
    "\n",
    "    train_dataset = DATALoader(\n",
    "        data=df_train.text.values,\n",
    "        target=df_train.label.values,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=8,\n",
    "        num_workers=4,\n",
    "    )\n",
    "\n",
    "    val_dataset = DATALoader(\n",
    "        data=df_valid.text.values,\n",
    "        target=df_valid.label.values,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    val_data_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=4,\n",
    "        num_workers=1,\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = BERTClassification()\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\n",
    "        \"bias\", \n",
    "        \"LayerNorm,bias\",\n",
    "        \"LayerNorm.weight\",\n",
    "               ]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n,p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "                   'weight_decay':0.001},\n",
    "        {'params': [p for n,p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "                   'weight_decay':0.0}\n",
    "    ]\n",
    "\n",
    "    num_train_steps = int(len(df_train)/ 8*10)\n",
    "\n",
    "    optimizers = AdamW(optimizer_parameters, lr=3e-5)\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizers,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_train_steps\n",
    "\n",
    "    )\n",
    "\n",
    "    best_accuracy = 0\n",
    "    for epoch in range(5):\n",
    "        train_func(data_loader=train_data_loader, model=model, optimizer=optimizers, device=device, scheduler=scheduler)\n",
    "        outputs, targets = eval_func(data_loader=train_data_loader, model=model, device=device)\n",
    "        outputs = np.array(outputs) >= 0.5\n",
    "        accuracy = metrics.accuracy_score()\n",
    "        print(f\"Accuracy Score: {accuracy}\")\n",
    "\n",
    "        if accuracy>best_accuracy:\n",
    "            torch.save(model.state_dict(), \"model.bin\")\n",
    "            best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c78e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4263bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eae530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a2a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75600982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
